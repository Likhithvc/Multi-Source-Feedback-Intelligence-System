<div align="center">

# ğŸ“Š Feedback Intelligence System

**Transform raw user feedback into actionable product insights**

![Python](https://img.shields.io/badge/Python-3.9+-3776AB?style=flat&logo=python&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-Dashboard-FF4B4B?style=flat&logo=streamlit&logoColor=white)
![SQLite](https://img.shields.io/badge/SQLite-Database-003B57?style=flat&logo=sqlite&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green?style=flat)

</div>

---

A production-ready feedback intelligence pipeline that collects user reviews from multiple sources (Google Play Store and external CSV uploads), performs sentiment analysis using both rule-based and transformer models, categorizes feedback, calculates priority scores, and generates actionable insights through an interactive dashboard and PDF reports.

<br>

## ğŸš€ Overview

This system automates the process of collecting, analyzing, and visualizing user feedback at scale. It fetches reviews from Google Play Store and imports feedback from external CSV files, applies natural language processing techniques to understand sentiment and categorize issues, then prioritizes feedback based on negativity, frequency, and recency. The results are stored in a SQLite database, exported to CSV, and visualized through an interactive Streamlit dashboard.

**Use Cases:**
- Product managers tracking user sentiment trends
- Development teams prioritizing bug fixes based on user impact
- Customer success teams identifying recurring pain points
- Stakeholders reviewing weekly feedback summaries via PDF reports

<br>

---

## âœ¨ Key Features

| Feature | Description |
|---------|-------------|
| **Google Play Store Integration** | Fetches up to 1000 reviews per run using the official scraper API |
| **CSV Upload Support** | Import feedback from external CSV files for batch processing |
| **Multi-Source Ingestion** | Combines data from all sources using pandas.concat() with proper source tracking |
| **Dual Sentiment Analysis** | Combines NLTK VADER (fast, rule-based) with HuggingFace DistilBERT (accurate, transformer-based) |
| **Keyword-Based Categorization** | Classifies feedback into Bug, Feature Request, Performance, UI/UX, or Other |
| **Priority Scoring Algorithm** | Multiplicative decay formula prioritizing recent, negative, frequent issues |
| **Trend Detection** | Identifies improving, declining, or stable sentiment patterns over time |
| **SQLite Persistence** | Stores all processed feedback with full schema |
| **CSV Export** | Timestamped exports for external analysis |
| **PDF Reports** | Auto-generated weekly summaries with sentiment breakdown and top issues |
| **Interactive Dashboard** | Streamlit-based UI with filters, charts, and data tables |

<br>

---

## ğŸ§  System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FEEDBACK INTELLIGENCE SYSTEM                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚   â”‚ Google Play  â”‚    â”‚  CSV Upload  â”‚                               â”‚
â”‚   â”‚  (Live API)  â”‚    â”‚   (Batch)    â”‚                               â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚          â”‚                   â”‚                                       â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                    â–¼                                                 â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚          â”‚  pandas.concat() â”‚                                        â”‚
â”‚          â”‚  (Merge Sources) â”‚                                        â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚                   â–¼                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚   â”‚   Cleaner    â”‚â”€â”€â”€â–¶â”‚  Sentiment   â”‚â”€â”€â”€â–¶â”‚  Categorizer â”‚          â”‚
â”‚   â”‚  (text prep) â”‚    â”‚  (VADER +    â”‚    â”‚  (keywords)  â”‚          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  Transformer)â”‚    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚                   â”‚
â”‚                                                  â”‚                   â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚          â–¼                                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚   â”‚   Priority   â”‚â”€â”€â”€â–¶â”‚    Trend     â”‚â”€â”€â”€â–¶â”‚   Storage    â”‚          â”‚
â”‚   â”‚   Scoring    â”‚    â”‚   Analysis   â”‚    â”‚  (DB + CSV)  â”‚          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                  â”‚                   â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚          â–¼                                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚   â”‚   SQLite     â”‚    â”‚     CSV      â”‚    â”‚     PDF      â”‚          â”‚
â”‚   â”‚   Database   â”‚    â”‚    Export    â”‚    â”‚    Report    â”‚          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                  STREAMLIT DASHBOARD                         â”‚   â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚   â”‚  â”‚ Filters â”‚  â”‚ Metrics â”‚  â”‚ Charts  â”‚  â”‚ Priority Table  â”‚ â”‚   â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

<br>

---

## ğŸ›  Tech Stack

| Component | Technology |
|-----------|------------|
| Language | Python 3.10+ |
| Data Processing | Pandas |
| Sentiment (Rule-based) | NLTK VADER |
| Sentiment (ML) | HuggingFace Transformers (DistilBERT) |
| Data Fetching | google-play-scraper |
| Database | SQLite + SQLAlchemy ORM |
| Dashboard | Streamlit |
| Visualization | Matplotlib |
| PDF Generation | ReportLab |

<br>

---

## ï¿½ Multi-Source Integration

The system supports multiple feedback sources that are combined into a unified processing pipeline:

| Source | Type | Description |
|--------|------|-------------|
| **Google Play Store** | Live API | Fetches up to 1000 reviews in real-time using `google-play-scraper` |
| **CSV Upload** | Batch File | Imports feedback from `data/external_feedback.csv` (optional) |

### How Sources Are Merged

1. **Fetch Phase**: Each source is fetched independently
   - Google Play: Live API call via `src/fetchers/google_play.py`
   - CSV: File load via `src/fetchers/csv_loader.py`

2. **Combine Phase**: DataFrames are merged using `pandas.concat()`
   - `ignore_index=True` ensures clean row indices
   - `source` column preserved (`google_play` or `CSV Upload`)

3. **Graceful Handling**:
   - If CSV file doesn't exist, pipeline continues with Google Play data only
   - If Google Play fails, pipeline continues with CSV data only
   - Record counts are printed per source for transparency

### CSV File Format

External CSV files must have these columns:
```
content,rating,date
"Great app!",5,2026-02-20
"Crashes often",1,2026-02-19
```

<br>

---

## ğŸ“ Folder Structure

```
feedback-intelligence-system/
â”‚
â”œâ”€â”€ app.py                       # Main entry point
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ .gitignore                   # Git ignore rules
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ fetchers/
â”‚   â”‚   â”œâ”€â”€ google_play.py       # Google Play Store scraper
â”‚   â”‚   â””â”€â”€ csv_loader.py        # CSV file loader
â”‚   â”‚
â”‚   â”œâ”€â”€ processing/
â”‚   â”‚   â”œâ”€â”€ cleaner.py           # Text preprocessing
â”‚   â”‚   â”œâ”€â”€ sentiment.py         # VADER + Transformer sentiment
â”‚   â”‚   â””â”€â”€ categorizer.py       # Keyword-based categorization
â”‚   â”‚
â”‚   â”œâ”€â”€ intelligence/
â”‚   â”‚   â”œâ”€â”€ trend.py             # Sentiment trend analysis
â”‚   â”‚   â””â”€â”€ priority.py          # Priority scoring algorithm
â”‚   â”‚
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ db.py                # SQLAlchemy engine & session
â”‚   â”‚   â””â”€â”€ models.py            # Feedback ORM model
â”‚   â”‚
â”‚   â”œâ”€â”€ reports/
â”‚   â”‚   â””â”€â”€ pdf_report.py        # PDF report generator (unused)
â”‚   â”‚
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ pipeline.py          # Main orchestration logic
â”‚       â”œâ”€â”€ storage_service.py   # Database & CSV storage
â”‚       â”œâ”€â”€ trend_service.py     # Trend analysis wrapper
â”‚       â””â”€â”€ report_service.py    # PDF report generation
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app.py                   # Streamlit dashboard
â”‚
â””â”€â”€ data/
    â”œâ”€â”€ external_feedback.csv    # External CSV input (optional)
    â”œâ”€â”€ feedback.db              # SQLite database (generated)
    â”œâ”€â”€ processed_feedback_*.csv # Exported CSV files (generated)
    â””â”€â”€ weekly_report_*.pdf      # PDF reports (generated)
```

<br>

---

## âš™ï¸ Installation

### Prerequisites

- Python **3.10** or higher
- pip package manager

### Steps

1. **Clone the repository**

   ```bash
   git clone https://github.com/yourusername/feedback-intelligence-system.git
   cd feedback-intelligence-system
   ```

2. **Create virtual environment**

   ```bash
   python -m venv myenv
   ```
   
   ```bash
   # Windows
   myenv\Scripts\activate
   
   # macOS/Linux
   source myenv/bin/activate
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

4. **Download NLTK data** *(happens automatically on first run)*

   ```bash
   python -c "import nltk; nltk.download('vader_lexicon')"
   ```

<br>

---

## â–¶ï¸ How to Run

### Run the Pipeline

Fetches reviews, processes them, stores to database, exports CSV, and generates PDF report.

```bash
python app.py
```

<details>
<summary><b>View expected output</b></summary>

```
==================================================
Feedback Intelligence System
==================================================
Fetching Google Play reviews...
  Fetched 1000 Google Play reviews
Fetching CSV feedback...
  Fetched 150 CSV records

Records fetched per source:
  - Google Play: 1000
  - CSV: 150
Total feedback collected: 1150

Processing feedback...
  Initializing sentiment analyzer...
  Cleaning text...
  Running VADER sentiment analysis...
  Running Transformer sentiment analysis...
  Categorizing feedback...
  Calculating priority scores...
Processing complete. 1150 records processed.

Storing to database...
  Stored 1150 records to database

Saved processed data to data/processed_feedback_20260224_143052.csv

Running trend analysis...
  Overall trend: stable
  Average sentiment: 0.127

Generating PDF report...
  Report saved to data/weekly_report_20260224.pdf

==================================================
Pipeline complete!
==================================================
```

</details>

### Run the Dashboard

Interactive web interface for exploring feedback data.

```bash
streamlit run dashboard/app.py
```

> Opens at `http://localhost:8501`

<br>

---

## ğŸ“¦ Output Artifacts

| Artifact | Location | Description |
|----------|----------|-------------|
| **SQLite Database** | `data/feedback.db` | Persistent storage of all processed feedback |
| **CSV Export** | `data/processed_feedback_YYYYMMDD_HHMMSS.csv` | Timestamped export for analysis |
| **PDF Report** | `data/weekly_report_YYYYMMDD.pdf` | Summary report with charts |

### Database Schema

```sql
CREATE TABLE feedback (
    id              INTEGER PRIMARY KEY AUTOINCREMENT,
    content         TEXT NOT NULL,
    source          VARCHAR(50) NOT NULL,
    rating          FLOAT,
    sentiment_label VARCHAR(20),
    sentiment_score FLOAT,
    category        VARCHAR(50),
    priority_score  FLOAT,
    date            DATETIME
);
```

<br>

---

## ğŸ“Š Dashboard Capabilities

| Feature | Description |
|---------|-------------|
| **Date Range Filter** | Filter feedback by date period |
| **Source Filter** | Filter by data source (google_play, CSV Upload) |
| **Sentiment Filter** | Filter by positive/negative/neutral |
| **Metrics Cards** | Total count, avg sentiment, positive %, negative % |
| **Sentiment Pie Chart** | Visual distribution of sentiment labels |
| **Trend Line Chart** | Daily sentiment score over time |
| **Category Bar Chart** | Feedback count by category |
| **Top Issues Table** | Categories ranked by frequency with avg scores |
| **High Priority Table** | Top 10 urgent feedback items |

<br>

---

## ğŸ’¡ Design Decisions

### Why VADER + Transformer?

- **VADER** is fast, requires no GPU, and performs well on social media text with emojis and slang. It's used as the primary sentiment source.
- **DistilBERT Transformer** provides higher accuracy for nuanced text. Both are computed and stored, allowing future analysis to compare or ensemble results.

### Why Multiplicative Priority Decay?

The priority formula `(negativity Ã— recency_weight Ã— 80) + (frequency Ã— 3)` uses multiplication rather than addition because:

- A very negative review from 30+ days ago should **NOT** remain high priority
- Recency acts as a decay factor: even strong negativity fades over time
- This prevents stale issues from dominating the priority list

### Why Simulated Dates?

Reviews are distributed across the last 7 days using `df.index % 7` to demonstrate the trend analysis feature. In production, actual review timestamps would be preserved.

<br>

---

## âš ï¸ Limitations

| Limitation | Details |
|------------|---------|
| **Single Data Source** | Currently only fetches from Google Play Store |
| **English Only** | Sentiment models trained on English text |
| **Keyword Categorization** | Simple keyword matching; no ML-based classification |
| **No Real-time Updates** | Batch processing only; no streaming |
| **Local Storage** | SQLite not suitable for distributed deployments |
| **No Authentication** | Dashboard has no access control |

<br>

---

## ğŸ”® Future Improvements

- [ ] Implement Reddit/Twitter social media fetchers
- [ ] Add ML-based topic modeling (LDA, BERTopic)
- [ ] Implement real-time streaming pipeline
- [ ] Add user authentication to dashboard
- [ ] Migrate to PostgreSQL for production
- [ ] Add email alerts for negative sentiment spikes
- [ ] Implement A/B comparison between app versions
- [ ] Add export to Google Sheets / Notion

<br>

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

<br>

---

## ğŸ‘¤ Author

**Likhith V C**

- ğŸ“§ Email: likhithvc21@gmail.com
- ğŸ™ GitHub: [@likhithvc](https://github.com/likhithvc)
- ğŸ’¼ LinkedIn: [Likhith V C](https://linkedin.com/in/likhithvc)

<br>

---

<div align="center">

*Last updated: February 2026*

</div>
